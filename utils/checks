import pandas as pd
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import logging
from dataclasses import dataclass
from enum import Enum

class RiskLevel(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"

@dataclass
class RiskResult:
    risk_level: RiskLevel
    score: float
    reasons: List[str]
    applied_rules: List[str]
    
class CriminalRecordRiskEngine:
    """
    A rule-based AI engine for assessing criminal record risk based on CSV configurations.
    Processes Checkr Trust API JSON data and outputs low/medium/high risk assessments.
    """
    
    def __init__(self, rule_set_path: str = "../rule_set"):
        """
        Initialize the risk assessment engine with CSV rule configurations.
        
        Args:
            rule_set_path: Path to the folder containing CSV rule files
        """
        self.rule_set_path = Path(rule_set_path)
        self.logger = logging.getLogger(__name__)
        
        # Initialize rule dataframes
        self.risk_scores = None
        self.categories = None
        self.charge_types = None
        self.depositions = None
        self.lookback_periods = None
        self.record_classes = None
        self.dob_config = None
        
        # Load all rule configurations
        self._load_configurations()
        
    def _load_configurations(self):
        """Load all CSV rule configurations into pandas DataFrames."""
        try:
            self.logger.info(f"Looking for CSV files in: {self.rule_set_path.absolute()}")
            
            # Check if rule_set directory exists
            if not self.rule_set_path.exists():
                self.logger.warning(f"Rule set directory does not exist: {self.rule_set_path}")
                return
            
            # Load risk score mappings
            risk_score_path = self.rule_set_path / "risk_score.csv"
            if risk_score_path.exists():
                self.risk_scores = pd.read_csv(risk_score_path)
                self.logger.info(f"Loaded risk_score.csv: {len(self.risk_scores)} rows")
            else:
                self.logger.warning(f"risk_score.csv not found at {risk_score_path}")
                
            # Load category mappings
            categories_path = self.rule_set_path / "categories1.csv"
            if categories_path.exists():
                self.categories = pd.read_csv(categories_path)
                self.logger.info(f"Loaded categories1.csv: {len(self.categories)} rows")
            else:
                self.logger.warning(f"categories1.csv not found at {categories_path}")
                
            # Load charge type classifications
            charge_types_path = self.rule_set_path / "charge_type_class.csv"
            if charge_types_path.exists():
                self.charge_types = pd.read_csv(charge_types_path)
                self.logger.info(f"Loaded charge_type_class.csv: {len(self.charge_types)} rows")
            else:
                self.logger.warning(f"charge_type_class.csv not found at {charge_types_path}")
                
            # Load disposition mappings
            deposition_path = self.rule_set_path / "deposition.csv"
            if deposition_path.exists():
                self.depositions = pd.read_csv(deposition_path)
                self.logger.info(f"Loaded deposition.csv: {len(self.depositions)} rows")
            else:
                self.logger.warning(f"deposition.csv not found at {deposition_path}")
                
            # Load lookback period configuration
            lookback_path = self.rule_set_path / "look_back.csv"
            if lookback_path.exists():
                self.lookback_periods = pd.read_csv(lookback_path)
                self.logger.info(f"Loaded look_back.csv: {len(self.lookback_periods)} rows")
            else:
                self.logger.warning(f"look_back.csv not found at {lookback_path}")
                
            # Load record class configurations
            record_classes_path = self.rule_set_path / "record_classes.csv"
            if record_classes_path.exists():
                self.record_classes = pd.read_csv(record_classes_path)
                # Clean column names - remove whitespace
                if self.record_classes is not None:
                    self.record_classes.columns = self.record_classes.columns.str.strip()
                self.logger.info(f"Loaded record_classes.csv: {len(self.record_classes)} rows")
            else:
                self.logger.warning(f"record_classes.csv not found at {record_classes_path}")
                
            # Load DOB configuration
            dob_path = self.rule_set_path / "dob.csv"
            if dob_path.exists():
                self.dob_config = pd.read_csv(dob_path)
                self.logger.info(f"Loaded dob.csv: {len(self.dob_config)} rows")
            else:
                self.logger.warning(f"dob.csv not found at {dob_path}")
                
            self.logger.info("Configuration loading completed")
            
        except Exception as e:
            self.logger.error(f"Error loading configurations: {str(e)}")
            raise
    
    def _get_lookback_period_days(self) -> int:
        """Get the selected lookback period in days from configuration."""
        if self.lookback_periods is None:
            return 7 * 365  # Default 7 years
            
        try:
            # Find the selected lookback period
            # Convert to string first to handle different data types
            select_column = self.lookback_periods['Please select ONE'].astype(str).str.upper()
            selected = self.lookback_periods[select_column == 'YES']
            
            if not selected.empty:
                years = float(selected.iloc[0]['Lookback Period (input)'])
                days = int(years * 365)
                self.logger.info(f"Using lookback period: {years} years ({days} days)")
                return days
            else:
                self.logger.warning("No lookback period selected, using default 7 years")
                return 7 * 365  # Default 7 years
                
        except Exception as e:
            self.logger.warning(f"Error parsing lookback period: {e}")
            return 7 * 365
    
    def _parse_date(self, date_str: str) -> Optional[datetime]:
        """Parse date string in various formats."""
        if not date_str:
            return None
            
        # Common date formats in background check data
        formats = [
            '%Y%m%d',      # 20160623
            '%Y-%m-%d',    # 2016-06-23
            '%m/%d/%Y',    # 06/23/2016
            '%d/%m/%Y',    # 23/06/2016
        ]
        
        for fmt in formats:
            try:
                return datetime.strptime(str(date_str), fmt)
            except ValueError:
                continue
                
        self.logger.warning(f"Could not parse date: {date_str}")
        return None
    
    def _is_within_lookback_period(self, offense_date: str) -> bool:
        """Check if offense date is within the configured lookback period."""
        if not offense_date:
            return True  # Include if no date available
            
        parsed_date = self._parse_date(offense_date)
        if not parsed_date:
            return True  # Include if date cannot be parsed
            
        lookback_days = self._get_lookback_period_days()
        cutoff_date = datetime.now() - timedelta(days=lookback_days)
        
        return parsed_date >= cutoff_date
    
    def _get_charge_type_risk_score(self, charge_type: str) -> float:
        """Get risk score for a specific charge type."""
        if self.charge_types is not None:
            try:
                # Clean and normalize charge type
                charge_type_clean = str(charge_type).lower().strip()
                
                # Find the correct column names (flexible matching)
                charge_type_col = None
                risk_score_col = None
                
                for col in self.charge_types.columns:
                    col_lower = col.lower().strip()
                    if 'charge' in col_lower and 'type' in col_lower:
                        charge_type_col = col
                    elif 'risk' in col_lower and 'score' in col_lower:
                        risk_score_col = col
                    elif col_lower in ['type', 'charge_type']:
                        charge_type_col = col
                    elif col_lower in ['score', 'risk_score']:
                        risk_score_col = col
                
                if charge_type_col and risk_score_col:
                    # Look for exact match first
                    exact_match = self.charge_types[
                        self.charge_types[charge_type_col].str.lower().str.strip() == charge_type_clean
                    ]
                    
                    if not exact_match.empty:
                        score = float(exact_match.iloc[0][risk_score_col])
                        self.logger.debug(f"Found exact match for charge type '{charge_type}': {score}")
                        return score
                    
                    # Look for partial matches
                    for _, row in self.charge_types.iterrows():
                        csv_charge_type = str(row[charge_type_col]).lower().strip()
                        if csv_charge_type in charge_type_clean or charge_type_clean in csv_charge_type:
                            score = float(row[risk_score_col])
                            self.logger.debug(f"Found partial match for charge type '{charge_type}' -> '{csv_charge_type}': {score}")
                            return score
                else:
                    self.logger.warning(f"Could not find charge type or risk score columns in CSV. Columns: {list(self.charge_types.columns)}")
                        
            except Exception as e:
                self.logger.warning(f"Error processing charge type from CSV {charge_type}: {e}")
        
        # Fallback to built-in logic if CSV not available or no match found
        charge_type_clean = str(charge_type).lower().strip()
        
        # Define risk mappings based on common charge types
        high_risk_types = ['felony', 'violent', 'drug trafficking', 'sexual offense']
        medium_risk_types = ['misdemeanor', 'petty_offense', 'traffic']
        low_risk_types = ['infraction', 'violation']
        
        for high_type in high_risk_types:
            if high_type in charge_type_clean:
                return 0.8
                
        for medium_type in medium_risk_types:
            if medium_type in charge_type_clean:
                return 0.5
                
        for low_type in low_risk_types:
            if low_type in charge_type_clean:
                return 0.2
                
        return 0.5  # Default medium risk
    
    def _get_disposition_risk_multiplier(self, disposition_type: str) -> float:
        """Get risk multiplier based on disposition type."""
        if not disposition_type:
            return 1.0
            
        if self.depositions is not None:
            try:
                disposition_clean = str(disposition_type).lower().strip()
                
                # Find the correct column names (flexible matching)
                disposition_col = None
                multiplier_col = None
                
                for col in self.depositions.columns:
                    col_lower = col.lower().strip()
                    if 'disposition' in col_lower:
                        disposition_col = col
                    elif 'multiplier' in col_lower or ('risk' in col_lower and 'multiplier' in col_lower):
                        multiplier_col = col
                    elif col_lower in ['type', 'disposition_type']:
                        disposition_col = col
                    elif col_lower in ['multiplier', 'risk_multiplier']:
                        multiplier_col = col
                
                if disposition_col and multiplier_col:
                    # Look for exact match first
                    exact_match = self.depositions[
                        self.depositions[disposition_col].str.lower().str.strip() == disposition_clean
                    ]
                    
                    if not exact_match.empty:
                        multiplier = float(exact_match.iloc[0][multiplier_col])
                        self.logger.debug(f"Found exact match for disposition '{disposition_type}': {multiplier}")
                        return multiplier
                    
                    # Look for partial matches
                    for _, row in self.depositions.iterrows():
                        csv_disposition = str(row[disposition_col]).lower().strip()
                        if csv_disposition in disposition_clean or disposition_clean in csv_disposition:
                            multiplier = float(row[multiplier_col])
                            self.logger.debug(f"Found partial match for disposition '{disposition_type}' -> '{csv_disposition}': {multiplier}")
                            return multiplier
                else:
                    self.logger.warning(f"Could not find disposition or multiplier columns in CSV. Columns: {list(self.depositions.columns)}")
                        
            except Exception as e:
                self.logger.warning(f"Error processing disposition from CSV {disposition_type}: {e}")
        
        # Fallback to built-in logic if CSV not available or no match found
        disposition_clean = str(disposition_type).lower().strip()
        
        # Define disposition risk multipliers
        if 'conviction' in disposition_clean:
            return 1.0  # Full risk
        elif 'pending' in disposition_clean:
            return 0.7  # Reduced risk for pending cases
        elif 'dismissed' in disposition_clean or 'acquitted' in disposition_clean:
            return 0.3  # Much lower risk for dismissed/acquitted
        elif 'unclassified' in disposition_clean or 'unknown' in disposition_clean:
            return 0.6  # Moderate risk for unclear dispositions
        else:
            return 0.8  # Default moderate-high risk
    
    def _should_include_record_category(self, category: str) -> bool:
        """Check if a record category should be included based on configuration."""
        if self.record_classes is None:
            return True
            
        try:
            # Find matching record category
            matches = self.record_classes[
                self.record_classes['Record Category'].str.contains(
                    str(category), case=False, na=False
                )
            ]
            
            if not matches.empty:
                # Check the filter column
                filter_col = None
                for col in self.record_classes.columns:
                    if 'filter' in col.lower() and 'include' in col.lower():
                        filter_col = col
                        break
                
                if filter_col:
                    filter_value = matches.iloc[0][filter_col]
                    return str(filter_value).lower().strip() == 'yes'
            
            return True  # Default to include if not found
            
        except Exception as e:
            self.logger.warning(f"Error checking record category {category}: {e}")
            return True
    
    def _calculate_base_risk_score(self, checkr_data: Dict[str, Any]) -> Tuple[float, List[str], List[str]]:
        """Calculate base risk score from criminal record data."""
        total_score = 0.0
        total_weight = 0.0
        reasons = []
        applied_rules = []
        
        results = checkr_data.get('results', [])
        
        for result in results:
            category = result.get('category', '')
            
            # Check if this category should be included
            if not self._should_include_record_category(category):
                applied_rules.append(f"Excluded category: {category}")
                continue
                
            cases = result.get('cases', [])
            
            for case in cases:
                case_number = case.get('case_number', 'Unknown')
                charges = case.get('charges', [])
                
                for charge in charges:
                    offense_date = charge.get('offense_date', '')
                    
                    # Check lookback period
                    if not self._is_within_lookback_period(offense_date):
                        applied_rules.append(f"Case {case_number}: Outside lookback period")
                        continue
                    
                    # Get charge type risk score
                    charge_type = charge.get('type', 'unknown')
                    base_score = self._get_charge_type_risk_score(charge_type)
                    
                    # Get disposition multiplier
                    dispositions = charge.get('dispositions', [])
                    disposition_multiplier = 1.0
                    
                    if dispositions:
                        disposition_type = dispositions[0].get('disposition_type', '')
                        disposition_multiplier = self._get_disposition_risk_multiplier(disposition_type)
                    
                    # Calculate weighted score
                    weighted_score = base_score * disposition_multiplier
                    total_score += weighted_score
                    total_weight += 1.0
                    
                    # Add reasoning
                    description = charge.get('description', 'No description')
                    subcategory = charge.get('subcategory', '')
                    
                    reason = f"Case {case_number}: {charge_type} - {description}"
                    if subcategory:
                        reason += f" ({subcategory})"
                    if disposition_multiplier != 1.0:
                        reason += f" [Disposition adjusted: {disposition_multiplier:.1f}x]"
                    
                    reasons.append(reason)
                    applied_rules.append(f"Processed: {charge_type} with disposition multiplier {disposition_multiplier}")
        
        # Calculate average risk score
        if total_weight > 0:
            average_score = total_score / total_weight
        else:
            average_score = 0.0
            reasons.append("No applicable criminal records found")
            applied_rules.append("Default: No records within criteria")
        
        return average_score, reasons, applied_rules
    
    def _determine_risk_level(self, score: float, record_count: int) -> RiskLevel:
        """Determine final risk level based on score and record count."""
        # Use risk_scores CSV if available, otherwise use default thresholds
        if self.risk_scores is not None:
            try:
                # Your CSV has 'Risk Score ' column with values like 'Low', 'Med', 'High'
                # We can use this for mapping, but we need to match categories first
                
                # For now, let's use the Risk Score column to understand the mapping
                # Look for any entries that might give us thresholds
                
                # Since your CSV doesn't have score ranges, we'll use the default logic
                # but could potentially enhance this later by mapping categories to scores
                
                self.logger.debug(f"Risk scores CSV available but no clear score ranges found")
                        
            except Exception as e:
                self.logger.warning(f"Error using risk_scores CSV: {e}")
        
        # Use default logic with your actual data structure
        # Adjust thresholds based on number of records
        if record_count == 0:
            return RiskLevel.LOW
        elif record_count >= 5:
            # Multiple records increase risk threshold sensitivity
            if score >= 0.6:
                return RiskLevel.HIGH
            elif score >= 0.3:
                return RiskLevel.MEDIUM
            else:
                return RiskLevel.LOW
        else:
            # Standard thresholds for fewer records
            if score >= 0.7:
                return RiskLevel.HIGH
            elif score >= 0.4:
                return RiskLevel.MEDIUM
            else:
                return RiskLevel.LOW
    
    def assess_risk(self, checkr_data: Dict[str, Any]) -> RiskResult:
        """
        Assess risk level based on criminal record data from Checkr API.
        
        Args:
            checkr_data: JSON data from Checkr Trust API
            
        Returns:
            RiskResult containing risk level, score, reasons, and applied rules
        """
        try:
            # Calculate base risk score
            score, reasons, applied_rules = self._calculate_base_risk_score(checkr_data)
            
            # Count total applicable records
            record_count = len([r for r in reasons if not r.startswith("No applicable")])
            
            # Determine final risk level
            risk_level = self._determine_risk_level(score, record_count)
            
            # Add summary reasoning
            if record_count > 0:
                reasons.insert(0, f"Found {record_count} applicable criminal record(s)")
                reasons.append(f"Average risk score: {score:.2f}")
            
            applied_rules.append(f"Final classification: {risk_level.value} risk")
            
            return RiskResult(
                risk_level=risk_level,
                score=score,
                reasons=reasons,
                applied_rules=applied_rules
            )
            
        except Exception as e:
            self.logger.error(f"Error in risk assessment: {str(e)}")
            return RiskResult(
                risk_level=RiskLevel.MEDIUM,
                score=0.5,
                reasons=[f"Error in assessment: {str(e)}"],
                applied_rules=["Error handling applied"]
            )
    
    def get_configuration_summary(self) -> Dict[str, Any]:
        """Get a summary of loaded configurations for debugging."""
        summary = {}
        
        if self.lookback_periods is not None:
            summary['lookback_period_days'] = self._get_lookback_period_days()
        
        if self.record_classes is not None:
            summary['total_record_classes'] = len(self.record_classes)
            
        summary['loaded_configs'] = {
            'risk_scores': self.risk_scores is not None,
            'categories': self.categories is not None,
            'charge_types': self.charge_types is not None,
            'depositions': self.depositions is not None,
            'lookback_periods': self.lookback_periods is not None,
            'record_classes': self.record_classes is not None,
            'dob_config': self.dob_config is not None,
        }
        
        return summary
    
    def reload_configurations(self):
        """Reload all CSV configurations without restarting the engine."""
        self.logger.info("Reloading configurations...")
        self._load_configurations()
        
    def validate_configuration(self) -> Dict[str, bool]:
        """Validate that all required CSV configurations are properly loaded."""
        validation = {
            'lookback_periods_valid': False,
            'charge_types_valid': False,
            'depositions_valid': False,
            'record_classes_valid': False
        }
        
        # Validate lookback periods
        if self.lookback_periods is not None:
            required_cols = ['Lookback Period', 'Lookback Period (input)', 'Please select ONE']
            if all(col in self.lookback_periods.columns for col in required_cols):
                validation['lookback_periods_valid'] = True
        
        # Validate charge types - your CSV has 'Charge Type' and 'Filter' columns
        if self.charge_types is not None:
            required_cols = ['Charge Type', "Filter\nYes = Include No = Don't Include"]
            if all(col in self.charge_types.columns for col in required_cols):
                validation['charge_types_valid'] = True
            else:
                self.logger.info(f"Charge types validation: Looking for {required_cols}")
                self.logger.info(f"Available columns: {list(self.charge_types.columns)}")
                
        # Validate depositions - your CSV has 'Disposition' and 'Filter' columns  
        if self.depositions is not None:
            required_cols = ['Disposition', "Filter\nYes = Include No = Don't Include"]
            if all(col in self.depositions.columns for col in required_cols):
                validation['depositions_valid'] = True
            else:
                self.logger.info(f"Depositions validation: Looking for {required_cols}")
                self.logger.info(f"Available columns: {list(self.depositions.columns)}")
                
        # Validate record classes
        if self.record_classes is not None:
            required_cols = ['Record Category']
            if all(col in self.record_classes.columns for col in required_cols):
                validation['record_classes_valid'] = True
        
        return validation
    
    def debug_csv_structure(self):
        """Print the structure of all loaded CSV files for debugging."""
        print("=== CSV File Structure Debug ===")
        
        if self.charge_types is not None:
            print(f"\ncharge_type_class.csv ({len(self.charge_types)} rows):")
            print(f"Columns: {list(self.charge_types.columns)}")
            if len(self.charge_types) > 0:
                print("Sample data:")
                print(self.charge_types.head(3).to_string())
        
        if self.depositions is not None:
            print(f"\ndeposition.csv ({len(self.depositions)} rows):")
            print(f"Columns: {list(self.depositions.columns)}")
            if len(self.depositions) > 0:
                print("Sample data:")
                print(self.depositions.head(3).to_string())
        
        if self.lookback_periods is not None:
            print(f"\nlook_back.csv ({len(self.lookback_periods)} rows):")
            print(f"Columns: {list(self.lookback_periods.columns)}")
            if len(self.lookback_periods) > 0:
                print("Sample data:")
                print(self.lookback_periods.to_string())
        
        if self.risk_scores is not None:
            print(f"\nrisk_score.csv ({len(self.risk_scores)} rows):")
            print(f"Columns: {list(self.risk_scores.columns)}")
            if len(self.risk_scores) > 0:
                print("Sample data:")
                print(self.risk_scores.head(3).to_string())
        
        if self.record_classes is not None:
            print(f"\nrecord_classes.csv ({len(self.record_classes)} rows):")
            print(f"Columns: {list(self.record_classes.columns)}")
            if len(self.record_classes) > 0:
                print("Sample data:")
                print(self.record_classes.head(3).to_string())
        
        print("\n=== End CSV Debug ===")


def main():
    """Example usage with sample Checkr data."""
    
    # Sample Checkr Trust API response
    sample_data = {
        "id": "5448da6a-a432-4a6e-9843-641d5e2fdd80",
        "results": [
            {
                "category": "Criminal/traffic",
                "cases": [
                    {
                        "case_number": "16-2016-CT-009299-AXXX-MA",
                        "charges": [
                            {
                                "offense_date": "20160623",
                                "type": "unknown",
                                "dispositions": [{"disposition_type": "Unclassified"}],
                                "category": "unclassified"
                            }
                        ]
                    }
                ]
            },
            {
                "category": "Criminal/traffic", 
                "cases": [
                    {
                        "case_number": "2022TR030504 A",
                        "charges": [
                            {
                                "description": "SPEED/70 INTERSTTE (REQUIRES SPEED)",
                                "offense_date": "20221201",
                                "type": "petty_offense",
                                "dispositions": [{"disposition_type": "Conviction"}],
                                "category": "Vehicles & Traffic",
                                "subcategory": "Speeding"
                            }
                        ]
                    }
                ]
            },
            {
                "category": "Criminal/traffic",
                "cases": [
                    {
                        "case_number": "16-2016-CT-009298-AXXX-MA", 
                        "charges": [
                            {
                                "description": "LICENSE; KNOWINGLY OPER VEH W- DL SUSP, CANCELLED, REVOKED",
                                "offense_date": "20160623",
                                "type": "misdemeanor",
                                "dispositions": [{"disposition_type": "Pending"}],
                                "category": "Vehicles & Traffic",
                                "subcategory": "License & Registration"
                            }
                        ]
                    }
                ]
            }
        ]
    }
    
    # Initialize the risk assessment engine
    engine = CriminalRecordRiskEngine(rule_set_path="../rule_set")
    
    # Validate configuration
    validation = engine.validate_configuration()
    print("Configuration Validation:")
    for key, is_valid in validation.items():
        status = "✓ VALID" if is_valid else "✗ INVALID"
        print(f"  {key}: {status}")
    print()
    
    # Print configuration summary
    config_summary = engine.get_configuration_summary()
    print("Configuration Summary:")
    print(json.dumps(config_summary, indent=2))
    print("\n" + "="*50 + "\n")
    
    # Assess risk
    result = engine.assess_risk(sample_data)
    
    # Print results
    print(f"Risk Assessment Results:")
    print(f"Risk Level: {result.risk_level.value.upper()}")
    print(f"Risk Score: {result.score:.3f}")
    print(f"\nReasons:")
    for i, reason in enumerate(result.reasons, 1):
        print(f"  {i}. {reason}")
    
    print(f"\nApplied Rules:")
    for i, rule in enumerate(result.applied_rules, 1):
        print(f"  {i}. {rule}")
    
    # Show CSV structure for debugging
    print(f"\n" + "="*50)
    print("CSV Structure (for debugging):")
    engine.debug_csv_structure()


if __name__ == "__main__":
    # Set up logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    main()